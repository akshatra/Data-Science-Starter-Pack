{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pgVSgBBKtdbe"
   },
   "source": [
    "# Data Representation for Deep Learning\n",
    "\n",
    "The first neural network that we built for MNIST handwritten-digit recognition, we started from data stored in multidimensional arrays called **tensors**.  \n",
    "\n",
    "* Tensor is a container for data, where we store almost always numerical data. \n",
    "* Tensors are a generalization of matrices to an arbitrary number of dimensions. (a *dimension* is called an *axis* or *rank*.)\n",
    "\n",
    "A tensor is defined by three attributes:\n",
    "1. Number of axes or rank  (`ndim`)\n",
    "2. Shape (`shape`)\n",
    "3. Data type (`dtype`)\n",
    "\n",
    "We can obtain the number of tensor dimensions through `ndim` function on tensor, its shape can be obtained by `shape` function\n",
    "and the data type is obtained by `dtype` function.\n",
    "\n",
    "- Let's look at  different types of tensors. \n",
    "- For each tensor, we will print its **number of dimensions, shape** and **data type**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uaa-AMEhtVP6"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5r9F-xSNurdk"
   },
   "source": [
    "## Scalars (0D tensors)\n",
    "\n",
    "A tensor that contains only one number is called *scalar* or *scalar tensor* or *0-dimensional tensor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a97H_XcjuqmP",
    "outputId": "377ee018-a130-4231-e2ab-fa5a0e04791d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pNMPnkyd8tBa",
    "outputId": "c04ac21d-e1f5-45a1-8759-3c1208476f2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0v87u3WdyTmA",
    "outputId": "b277a344-6b50-49e1-8c8e-50b115673ff4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9LM-0WcDvrve",
    "outputId": "f3eb4b29-2ced-4024-9ad7-849bb8f0029b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IrpDmVLSwBaO"
   },
   "source": [
    "## Vectors (1D tensors)\n",
    "\n",
    "An array of numbers is called *vector* or *1D tensor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WIY5zAPBwFIu",
    "outputId": "01cd11ff-ac10-4e86-b41c-8a213925f2ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([4, 2, 5, 9])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RqojOQmswSd8",
    "outputId": "16f61f7f-bfd1-475e-d50e-1503db035df9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BiNU8LgewoIM"
   },
   "source": [
    "## Matrices (2D tensors)\n",
    "\n",
    "An array of vectors is a *matrix*, or *2D tensor*.\n",
    "\n",
    "A matrix has two axes: *rows* and *columns*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "mIMYclt2xFuq",
    "outputId": "e25d1fd7-d763-4b79-fdcf-ba9264041e1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3],\n",
    "              [4,5,6],\n",
    "              [7,8,9]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5lszf7yEEGVU"
   },
   "source": [
    "- The entries from the first axis are called the **rows**.  E.g.  $[1, 2, 3]$ is the first row of matrix x. \n",
    "- The entries from the second axis are called the **columns**.  E.g. $[1,4,7]$ is the first column of the matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nAHjNm9XxV9D",
    "outputId": "efe471f7-cd44-4923-9b27-dada246f5447"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j0RJwAYVxYHS",
    "outputId": "3fc488a6-5f66-42ca-e8c0-2ee5450f21c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y99WUv0Fen_q",
    "outputId": "52f99727-c1c1-4c47-b66d-bc887811e335"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtwTCaZjwcT2"
   },
   "source": [
    "## 3D Tensors\n",
    "\n",
    "We can pack matrices in an array to get 3D tensors.  Similarly we can pack 3D tensors in a new array, we get 4D tensors and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ioBqYf9wGYFj"
   },
   "outputs": [],
   "source": [
    "x = np.array([[[1,2,3],\n",
    "              [4,5,6],\n",
    "              [7,8,9]],\n",
    "            [[1,2,3],\n",
    "              [4,5,6],\n",
    "              [7,8,9]],\n",
    "            [[1,2,3],\n",
    "              [4,5,6],\n",
    "              [7,8,9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ss6Pe-J2Glz9",
    "outputId": "8b5bebb9-ceb4-4859-c254-28ac51ccc925"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NNg-Zc0mGnmg",
    "outputId": "96aabd49-44e5-4f98-e416-baeeb8dbc286"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N1UWX34vexIc",
    "outputId": "afe55750-0191-4db4-e177-6d6b40ea125a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODjv0ciRIYLG"
   },
   "source": [
    "## Tensor in MNIST datasets\n",
    "\n",
    "Let's check out tensors from the first TF model that we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "colab_type": "code",
    "id": "jcX8e6u7I0Qa",
    "outputId": "56b8a514-d545-4e8c-eab1-f7725683ef24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0-beta1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/43/dcf19f30fb1da9e971e591d95e56c7b9d4e417f4a203ad272eb746742f42/tensorflow-2.0.0b1-cp37-cp37m-manylinux1_x86_64.whl (88.7MB)\n",
      "\u001b[K     |████████████████████████████████| 88.7MB 214kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (0.1.8)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (0.2.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.17.4)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (3.11.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (0.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.0.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
      "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
      "\u001b[K     |████████████████████████████████| 501kB 7.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1MB 7.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.11.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.16.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (0.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (0.33.6)\n",
      "Requirement already satisfied: setuptools in /home/akshatra/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta1) (42.0.2.post20191203)\n",
      "Requirement already satisfied: h5py in /home/akshatra/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/akshatra/anaconda3/lib/python3.7/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/akshatra/.local/lib/python3.7/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (0.16.0)\n",
      "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
      "  Found existing installation: tensorflow 1.15.0\n",
      "    Uninstalling tensorflow-1.15.0:\n",
      "      Successfully uninstalled tensorflow-1.15.0\n",
      "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akshatra/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "!pip install tensorflow==2.0.0-beta1\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMEPpHC9_I6W"
   },
   "source": [
    "Let's load the MNIST dataset and look at x_train and y_train tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rkivR41sI6eh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "98SMpcyTI9pW",
    "outputId": "3ccad0ad-f064-452f-ffc4-c45e4da119b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of training data Tensor\n",
      "==================================\n",
      "Number of axes in tensor = 3\n",
      "Shape of a tensor: (60000, 28, 28)\n",
      "Data type of tensor elements: uint8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Attributes of training data Tensor\")\n",
    "print (\"==================================\")\n",
    "print (\"Number of axes in tensor = %d\"%x_train.ndim)\n",
    "print (\"Shape of a tensor:\", x_train.shape)\n",
    "print (\"Data type of tensor elements: %s\"%x_train.dtype)\n",
    "\n",
    "print (\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUHHAy9YKYBB"
   },
   "source": [
    "Training data tensor is an array of 60,000 matrices of 28x28 8-bit integers.  Each matrix is a grey-scale image with each pixel value between 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "gt_5-9ccKUla",
    "outputId": "4cf695fd-1ea7-4d01-86a7-6679a4014121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of training label Tensor\n",
      "===================================\n",
      "Number of axes in tensor = 1\n",
      "Shape of a tensor: (60000,)\n",
      "Data type of tensor elements: uint8\n"
     ]
    }
   ],
   "source": [
    "print (\"Attributes of training label Tensor\")\n",
    "print (\"===================================\")\n",
    "print (\"Number of axes in tensor = %d\"%y_train.ndim)\n",
    "print (\"Shape of a tensor:\", y_train.shape)\n",
    "print (\"Data type of tensor elements: %s\"%y_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JuoM6kxKK0gU"
   },
   "source": [
    "Training label tensor is a vector or 1D array of labels containing 60,000 entries.  Each element is a 8-bit integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlh1qrHKArwr"
   },
   "source": [
    "### Question\n",
    "Find out number of dimensions, shape and data type of x_test and y_test tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Sz3cw34Aa79"
   },
   "source": [
    "# Data Selection (Tensor Slicing)\n",
    "\n",
    "Selecting a specific elements in a tensor is called *tensor slicing*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kpZgXTmC_lLq"
   },
   "source": [
    "## Selecting a single data point\n",
    "\n",
    "Let's look at the first training example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HFwgxzbDry8m",
    "outputId": "bb04c3d0-0731-47e7-bba6-9af7810a56f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = x_train[0]\n",
    "x_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJuSNI1O_yZl"
   },
   "source": [
    "As you can see that there are 28 rows of 28 dimensional vectors and each position holds a number between 0 to 255.  Let's visualize the digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "jjIxVBQELMlc",
    "outputId": "938d60be-eb46-4011-d625-958e2c44388e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's display first image from the training set with Matplotlib.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to display an image.\n",
    "def display_image(img):\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "display_image(x_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mW7EuB5AzPT"
   },
   "source": [
    "### Question\n",
    "Write the code to look at the 11-th data point in the training set and display the number with the help of `imshow`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eq9fALjnMfh1",
    "outputId": "ed462158-ad60-4490-e62d-5c7e5a42557f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  42 118 219 166 118 118   6\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 103 242 254 254 254 254 254  66\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  18 232 254 254 254 254 254 238\n",
      "   70   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 104 244 254 224 254 254 254\n",
      "  141   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 207 254 210 254 254 254\n",
      "   34   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  84 206 254 254 254 254\n",
      "   41   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  24 209 254 254 254\n",
      "  171   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  91 137 253 254 254 254\n",
      "  112   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  40 214 250 254 254 254 254 254\n",
      "   34   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  81 247 254 254 254 254 254 254\n",
      "  146   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 110 246 254 254 254 254 254\n",
      "  171   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  73  89  89  93 240 254\n",
      "  171   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1 128 254\n",
      "  219  31   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7 254 254\n",
      "  214  28   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 138 254 254\n",
      "  116   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  19 177  90   0   0   0   0   0  25 240 254 254\n",
      "   34   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 164 254 215  63  36   0  51  89 206 254 254 139\n",
      "    8   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  57 197 254 254 222 180 241 254 254 253 213  11\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 140 105 254 254 254 254 254 254 236   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   7 117 117 165 254 254 239  50   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANnElEQVR4nO3dcaxU5ZnH8d+zbImJrQaWq0FQb7eSqNlkoZmQNWrD2iwR/xBRacCksoaEGkVLqImmS6yamBiyhWzMpnq7krJrF2xCjWiMWyVNDH/YOOgV0OsqC1dKuYFBQ4BEYbHP/nGPmyvceWeYc86c4T7fTzKZmfPMOe+T0R9nZt6Z+5q7C8DE9xdVNwCgOwg7EARhB4Ig7EAQhB0I4i+7Odi0adO8v7+/m0MCoQwPD+vIkSM2Xi1X2M3sZkn/ImmSpH9z96dSj+/v71e9Xs8zJICEWq3WtNbxy3gzmyTpXyUtkHStpKVmdm2nxwNQrjzv2edK2uPue939lKTNkhYW0xaAouUJ+wxJfxxz/0C27WvMbIWZ1c2s3mg0cgwHII88YR/vQ4Czvnvr7gPuXnP3Wl9fX47hAOSRJ+wHJF0+5v5MSQfztQOgLHnC/rakWWb2bTObLGmJpK3FtAWgaB1Pvbn7aTNbKem/NDr1tsHd3y+sMwCFyjXP7u6vSnq1oF4AlIivywJBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQRFeXbEY5Pvjgg6a1V155Jbnvs88+m6zPnTs3WZ8zZ06ynrJq1apkffLkyR0fG2fjzA4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDPfh5oNRf+0EMPNa2dOHEi19h79+5N1jdv3tzxsWu1WrJ+0003dXxsnC1X2M1sWNJxSV9KOu3u6f96ACpTxJn97939SAHHAVAi3rMDQeQNu0v6nZntMLMV4z3AzFaYWd3M6o1GI+dwADqVN+zXu/t3JS2QdL+Zfe/MB7j7gLvX3L3W19eXczgAncoVdnc/mF0flvSipPRPpABUpuOwm9mFZvatr25Lmi9pd1GNAShWnk/jL5X0opl9dZz/dPfXCukKX7N48eJk/dFHH21ayzvPXqY77rgjWX/hhReS9fnz5xfZzoTXcdjdfa+kvy2wFwAlYuoNCIKwA0EQdiAIwg4EQdiBIPiJ63lg6tSpyfrjjz/etLZ69erkvp9//nmyfsUVVyTr+/fvT9ZTjh49mqy/9lp6Jpept3PDmR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmCefQK49957m9aeeeaZ5L7vvfdesn7RRRd11FMRVq5cWdnYExFndiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0Ignn2CW7NmjXJ+pNPPpmsDw4OFtnOOTl58mRlY09EnNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjm2Se4O++8M1m/4YYbkvVWf5t9165d59xTu1p9R2DLli2ljT0RtTyzm9kGMztsZrvHbJtqZq+b2cfZ9ZRy2wSQVzsv438l6eYztj0iaZu7z5K0LbsPoIe1DLu7vynpszM2L5S0Mbu9UdJtBfcFoGCdfkB3qbuPSFJ2fUmzB5rZCjOrm1m90Wh0OByAvEr/NN7dB9y95u61vr6+socD0ESnYT9kZtMlKbs+XFxLAMrQadi3SlqW3V4m6aVi2gFQlpbz7Ga2SdI8SdPM7ICkn0l6StJvzGy5pP2SFpfZJDr3/PPPJ+s7d+5M1sucR2/lxhtvrGzsiahl2N19aZPS9wvuBUCJ+LosEARhB4Ig7EAQhB0IgrADQfAT1/PAhx9+mKwvWrSoaW3Pnj3JfU+fPt1RT91w6623Vt3ChMKZHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJ79PDA0NJSs79u3r2mtl+fRW1m/fn2y/vTTT3epk4mBMzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME8+3kg9Xt1SVq7dm3T2sMPP5zc94svvuiop244ePBg1S1MKJzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAI5tkngAcffLBpbdasWcl9jx49mmvsVr+XX7lyZdPasWPHco2Nc9PyzG5mG8zssJntHrPtMTP7k5kNZpdbym0TQF7tvIz/laSbx9m+3t1nZ5dXi20LQNFaht3d35T0WRd6AVCiPB/QrTSzndnL/CnNHmRmK8ysbmb1RqORYzgAeXQa9l9I+o6k2ZJGJP282QPdfcDda+5e6+vr63A4AHl1FHZ3P+TuX7r7nyX9UtLcYtsCULSOwm5m08fcXSRpd7PHAugNLefZzWyTpHmSppnZAUk/kzTPzGZLcknDkn5UYo/IYcGCBaUe392T9dT68E888URy38HBwWT9k08+SdavvPLKZD2almF396XjbH6uhF4AlIivywJBEHYgCMIOBEHYgSAIOxAEP3FFLqdOnUrWW02vpUyePDlZnzRpUsfHjogzOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTw7clmzZk1px16+fHmyPnPmzNLGnog4swNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEMyzt+nTTz9tWrvnnnuS+y5ZsiRZv+uuuzrqqRtGRkaS9YGBgdLGvv3220s7dkSc2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCObZ2/TAAw80rb388svJfT/66KNkfcaMGbnqV111VdPajh07kvu26m3t2rXJ+rFjx5L1lNWrVyfrl112WcfHxtlantnN7HIz+72ZDZnZ+2b242z7VDN73cw+zq6nlN8ugE618zL+tKSfuPs1kv5O0v1mdq2kRyRtc/dZkrZl9wH0qJZhd/cRd38nu31c0pCkGZIWStqYPWyjpNvKahJAfuf0AZ2Z9UuaI+kPki519xFp9B8ESZc02WeFmdXNrN5oNPJ1C6BjbYfdzL4paYukVe7e9qcy7j7g7jV3r/X19XXSI4ACtBV2M/uGRoP+a3f/bbb5kJlNz+rTJR0up0UARWg59WZmJuk5SUPuvm5MaaukZZKeyq5fKqXDHpGaetu3b19y37feeitZnzdvXrLe39+frF9zzTVNa9u3b0/ue/z48WQ9r6uvvrpprdVyzhdccEHR7YTWzjz79ZJ+KGmXmQ1m236q0ZD/xsyWS9ovaXE5LQIoQsuwu/t2Sdak/P1i2wFQFr4uCwRB2IEgCDsQBGEHgiDsQBD8xLVN1113XUc1Sbr77ruT9fvuuy9ZHx4ezlUv05Qp6R87Dg0NdakTtMKZHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJ69AOvWrUvWT548mayfOHEi1/jvvvtu09qmTZtyHfviiy9O1t94441cx0f3cGYHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSDM3bs2WK1W83q93rXxgGhqtZrq9fq4fw2aMzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBNEy7GZ2uZn93syGzOx9M/txtv0xM/uTmQ1ml1vKbxdAp9r54xWnJf3E3d8xs29J2mFmr2e19e7+z+W1B6Ao7azPPiJpJLt93MyGJM0ouzEAxTqn9+xm1i9pjqQ/ZJtWmtlOM9tgZuOuA2RmK8ysbmb1RqORq1kAnWs77Gb2TUlbJK1y92OSfiHpO5Jma/TM//Px9nP3AXevuXutr6+vgJYBdKKtsJvZNzQa9F+7+28lyd0PufuX7v5nSb+UNLe8NgHk1c6n8SbpOUlD7r5uzPbpYx62SNLu4tsDUJR2Po2/XtIPJe0ys8Fs208lLTWz2ZJc0rCkH5XSIYBCtPNp/HZJ4/0+9tXi2wFQFr5BBwRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCKKrSzabWUPSJ2M2TZN0pGsNnJte7a1X+5LorVNF9nalu4/799+6GvazBjeru3utsgYSerW3Xu1LordOdas3XsYDQRB2IIiqwz5Q8fgpvdpbr/Yl0VunutJbpe/ZAXRP1Wd2AF1C2IEgKgm7md1sZv9tZnvM7JEqemjGzIbNbFe2DHW94l42mNlhM9s9ZttUM3vdzD7OrsddY6+i3npiGe/EMuOVPndVL3/e9ffsZjZJ0keS/kHSAUlvS1rq7h90tZEmzGxYUs3dK/8Chpl9T9IJSf/u7n+TbVsr6TN3fyr7h3KKuz/cI709JulE1ct4Z6sVTR+7zLik2yT9oyp87hJ9/UBdeN6qOLPPlbTH3fe6+ylJmyUtrKCPnufub0r67IzNCyVtzG5v1Oj/LF3XpLee4O4j7v5Odvu4pK+WGa/0uUv01RVVhH2GpD+OuX9AvbXeu0v6nZntMLMVVTczjkvdfUQa/Z9H0iUV93Omlst4d9MZy4z3zHPXyfLneVUR9vGWkuql+b/r3f27khZIuj97uYr2tLWMd7eMs8x4T+h0+fO8qgj7AUmXj7k/U9LBCvoYl7sfzK4PS3pRvbcU9aGvVtDNrg9X3M//66VlvMdbZlw98NxVufx5FWF/W9IsM/u2mU2WtETS1gr6OIuZXZh9cCIzu1DSfPXeUtRbJS3Lbi+T9FKFvXxNryzj3WyZcVX83FW+/Lm7d/0i6RaNfiL/P5L+qYoemvT115Leyy7vV92bpE0afVn3vxp9RbRc0l9J2ibp4+x6ag/19h+SdknaqdFgTa+otxs0+tZwp6TB7HJL1c9doq+uPG98XRYIgm/QAUEQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ/wfhhB+6sgk0wwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Expand to check the solution\n",
    "# Check out 11-th image in the training set.\n",
    "i = 10\n",
    "x_i = x_train[i]\n",
    "print (x_i)\n",
    "display_image(x_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTt7huD1Nq_4"
   },
   "source": [
    "## Select multiple data points\n",
    "- : is used to select the entire axis.\n",
    "- i:j is used to select $i$-th to$ j-1$-th data points.  Note that $j$-th point is not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "WNOr-ZvGObS1",
    "outputId": "d0052f64-7bb9-46d5-dcc8-35a9707c7ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of data slice tensor\n",
      "===================================\n",
      "Number of axes in tensor = 3\n",
      "Shape of a tensor: (90, 28, 28)\n",
      "Data type of tensor elements: uint8\n"
     ]
    }
   ],
   "source": [
    "# select data point from 10 to 100 (100 is not included)\n",
    "x_train_slice = x_train[10:100]\n",
    "# print(x_train_slice)\n",
    "\n",
    "print (\"Attributes of data slice tensor\")\n",
    "print (\"===================================\")\n",
    "print (\"Number of axes in tensor = %d\"%x_train_slice.ndim)\n",
    "print (\"Shape of a tensor:\", x_train_slice.shape)\n",
    "print (\"Data type of tensor elements: %s\"%x_train_slice.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4aXR2AYhPDL_"
   },
   "source": [
    "There are a few more equivalent ways of doing the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "DyiYOUEaPCAO",
    "outputId": "6027066e-d94d-4aae-c93f-23c0398fc3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of data slice tensor\n",
      "===================================\n",
      "Number of axes in tensor = 3\n",
      "Shape of a tensor: (90, 28, 28)\n",
      "Data type of tensor elements: uint8\n"
     ]
    }
   ],
   "source": [
    "# Here we explicitely select the remaining two axes.\n",
    "x_train_slice = x_train[10:100, :, :]\n",
    "\n",
    "print (\"Attributes of data slice tensor\")\n",
    "print (\"===================================\")\n",
    "print (\"Number of axes in tensor = %d\"%x_train_slice.ndim)\n",
    "print (\"Shape of a tensor:\", x_train_slice.shape)\n",
    "print (\"Data type of tensor elements: %s\"%x_train_slice.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "Zbl-e2gZPVj7",
    "outputId": "dc2726ef-193d-4ca2-b6b2-12328aa8e349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of data slice tensor\n",
      "===============================\n",
      "Number of axes in tensor = 3\n",
      "Shape of a tensor: (90, 28, 28)\n",
      "Data type of tensor elements: uint8\n"
     ]
    }
   ],
   "source": [
    "# Here we explicitely select the remaining two axes by specifying the first and the last elements.\n",
    "x_train_slice = x_train[10:100, 0:28, 0:28]\n",
    "\n",
    "print (\"Attributes of data slice tensor\")\n",
    "print (\"===============================\")\n",
    "print (\"Number of axes in tensor = %d\"%x_train_slice.ndim)\n",
    "print (\"Shape of a tensor:\", x_train_slice.shape)\n",
    "print (\"Data type of tensor elements: %s\"%x_train_slice.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4DUJB7iPej5"
   },
   "source": [
    "## Questions:\n",
    "\n",
    "(1) Write the code to select bottom right patch of 14x14 from the training images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "Ku0aSt1NPdz1",
    "outputId": "de857800-8503-42f3-b19f-da747fc8c927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of data slice tensor\n",
      "===============================\n",
      "Number of axes in tensor = 3\n",
      "Shape of a tensor: (60000, 14, 14)\n",
      "Data type of tensor elements: uint8\n"
     ]
    }
   ],
   "source": [
    "#@title Expand to see the answer.\n",
    "x_train_br_slice = x_train[:, 14:, 14:]\n",
    "\n",
    "print (\"Attributes of data slice tensor\")\n",
    "print (\"===============================\")\n",
    "print (\"Number of axes in tensor = %d\"%x_train_br_slice.ndim)\n",
    "print (\"Shape of a tensor:\", x_train_br_slice.shape)\n",
    "print (\"Data type of tensor elements: %s\"%x_train_br_slice.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YX6wl99BP1ni"
   },
   "source": [
    "(2) Write the code to crop imags to patches of 14x14 pixel centered in the middle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "OxNvD-I4QW_f",
    "outputId": "d5d67ac6-f571-4887-91c4-9c3cbbaf8e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of data slice tensor\n",
      "===============================\n",
      "Number of axes in tensor = 3\n",
      "Shape of a tensor: (60000, 14, 14)\n",
      "Data type of tensor elements: uint8\n"
     ]
    }
   ],
   "source": [
    "#@title Expand to see the answer.\n",
    "x_train_br_slice = x_train[:, 7:-7, 7:-7]\n",
    "\n",
    "print (\"Attributes of data slice tensor\")\n",
    "print (\"===============================\")\n",
    "print (\"Number of axes in tensor = %d\"%x_train_br_slice.ndim)\n",
    "print (\"Shape of a tensor:\", x_train_br_slice.shape)\n",
    "print (\"Data type of tensor elements: %s\"%x_train_br_slice.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XonJcyG7pTaU"
   },
   "source": [
    "Since we consume data in batches during training (remember batch gradient descent?), let's understand how data batch tensors look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hCB6bnuYR82E"
   },
   "source": [
    "# Data Batches\n",
    "\n",
    "We usually break the data into small batches and process those batches:\n",
    "\n",
    "* The first axis in all data sensor is *sample axis* or *sample dimension*.  \n",
    "\n",
    "* The first axis of batch tensor is called the *batch axis* or *batch dimension*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "Jh4qQPoNS5UX",
    "outputId": "3f5cc063-dd41-46b8-8133-17f6e6c6a608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of data slice tensor\n",
      "===============================\n",
      "Number of axes in tensor = 3\n",
      "Shape of a tensor: (128, 28, 28)\n",
      "Data type of tensor elements: uint8\n",
      "\n",
      "Second batch:\n",
      "Attributes of data slice tensor\n",
      "===============================\n",
      "Number of axes in tensor = 3\n",
      "Shape of a tensor: (128, 28, 28)\n",
      "Data type of tensor elements: uint8\n"
     ]
    }
   ],
   "source": [
    "# First batch - first 128 examples.  Each batch has 128 examples.\n",
    "batch_1 = x_train[:128]\n",
    "print (\"Attributes of data slice tensor\")\n",
    "print (\"===============================\")\n",
    "print (\"Number of axes in tensor = %d\"%batch_1.ndim)\n",
    "print (\"Shape of a tensor:\", batch_1.shape)\n",
    "print (\"Data type of tensor elements: %s\"%batch_1.dtype)\n",
    "\n",
    "# Next batch - next 128 examples.\n",
    "batch_2 = x_train[128:256]\n",
    "print (\"\")\n",
    "print (\"Second batch:\")\n",
    "print (\"Attributes of data slice tensor\")\n",
    "print (\"===============================\")\n",
    "print (\"Number of axes in tensor = %d\"%batch_2.ndim)\n",
    "print (\"Shape of a tensor:\", batch_2.shape)\n",
    "print (\"Data type of tensor elements: %s\"%batch_2.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tB9HrsKETle_"
   },
   "source": [
    "### Question:\n",
    "Write the code to get $n$-th batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "4jiXi_v3TklZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of data slice tensor\n",
      "===============================\n",
      "Number of axes in tensor = 3\n",
      "Shape of a tensor: (128, 28, 28)\n",
      "Data type of tensor elements: uint8\n"
     ]
    }
   ],
   "source": [
    "#@title Expand the cell to see the solution.\n",
    "\n",
    "# Since the first batch starts at 0, in order to get n-th batch,\n",
    "# we \n",
    "n = 5\n",
    "batch_n = x_train[128*n:128*(n+1)]\n",
    "\n",
    "print (\"Attributes of data slice tensor\")\n",
    "print (\"===============================\")\n",
    "print (\"Number of axes in tensor = %d\"%batch_n.ndim)\n",
    "print (\"Shape of a tensor:\", batch_n.shape)\n",
    "print (\"Data type of tensor elements: %s\"%batch_n.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4ILeThWUMHB"
   },
   "source": [
    "# Real world examples of data tensors\n",
    "\n",
    "| Tensor| Example                             | Shape                                                 | Dataset                                 | \n",
    "|------------|:---------------------------------------:| :-----------------------------------------------------| :----------------------------------------:|\n",
    "| 2D        | Vector                                 |  `(samples, features)`  |  Text documents |\n",
    "| 3D        | Timeseries or Sequence | `(samples, timesteps, features)` |  Stock Prices |\n",
    "| 4D        | Images                               | `(samples, channels, height, width)`  |  MNIST Digit |                 \n",
    "| 5D        | Videos                               | `(samples, frames, channels, height, width)` | Videos |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3RRBIVGjEWk"
   },
   "source": [
    "## Vector data\n",
    "\n",
    "- Most commonly appearing tensor in ML\n",
    "- Each point is encoded as a vector of features\n",
    "- A batch of data can be encoded as a 2D tensor i.e. array of vectors\n",
    "   - First axis is a `sample axis`\n",
    "   - Second axis is a `feature axis` \n",
    "- What are the examples of such dataset?\n",
    "   - Text documents: A set of k documents, each represented with `m` features\n",
    "   - Fuel efficiency dataset: A set of automobiles and their features\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cdYWvVbtwaO"
   },
   "source": [
    "## Timeseries and sequence data\n",
    "\n",
    "We use 3D tensor for storing time-series and sequence data: `(samples, timesteps, features)`\n",
    "\n",
    "### Stock prices dataset\n",
    "- Every minute, we store features associated with that instance of time:  e.g. current price, the highest and the lowest price in the past minute. Thus every minute is encoded as a $m$-D vector, where $m$ is the number of features.  \n",
    "- An entire day of trading is encoded as a 2D tensor of shape (390, $m$) (there are 390 minutes in a trading\n",
    "day).\n",
    "- 250 days’ worth of data can be stored in a 3D tensor of shape (250, 390, $m$). Here, each sample would be one day’s worth of data.\n",
    "\n",
    "\n",
    "### Dataset of tweets\n",
    "Tweet is encoded as a sequence of 280 characters.  \n",
    "- At each position, one of the 128 unique characters is possible. Thus, each character can be encoded as a one-hot-encoding with 128 length vector. \n",
    "- Each tweet can be encoded as a 2D tensor of shape (280, 128).\n",
    "- A dataset of 1000000 can be stored in 3D tensor of shape (1000000, 280, 128)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zma0lNwFwKk0"
   },
   "source": [
    "## Video data\n",
    "\n",
    "- Stored as a 5D tensor of shape `(samples, frames, channels, height, width)`\n",
    "- Each sample is a video encoded in 4D tensor of shape `(frames, channels, height, width)`\n",
    "- Each frame in the video is encoded as a 3D tensor (just like images).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMmeYax7xGRL"
   },
   "source": [
    "#### Question\n",
    "Deduce the shape of a tensor to store 4 videos, where each video is a 60-second clip of size 128x256 sampled at 4 frames a second?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4G52_81q3hS"
   },
   "source": [
    "Now that we have studied how the data is represented in tensor, let's explore how they are used in NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G1Ssdrk-xz8n"
   },
   "source": [
    "# Key operations in Neural Networks\n",
    "\n",
    "\n",
    "In NN, we specify a layer with the following statement:\n",
    "\n",
    "`tf.keras.layers.Dense(128, activation='relu')`\n",
    "\n",
    "This layer takes 2D tensor as input and returns another 2D tensor as an output through the following function:\n",
    "\n",
    "`output = relu(dot(w, input)+b)`\n",
    "\n",
    "There are three operations here:\n",
    "1. Linear combination of inputs and the corresponding weights: `dot(w, input)` where `w` is a weight vector and `input` is a feature vector.\n",
    "2. Add bias to the calculation `dot(w, input)+b`\n",
    "3. Finally apply a non-linear activiation on the result.  Here we have used `relu` as an activation function, which returns `max(x, 0)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6l666tQuDJY"
   },
   "source": [
    "Let $m$ be the size of the input to this layer.  Since it's a dense layer, each unit/neuron in this layer will receive $m$ inputs per sample.   \n",
    "- For each neuron, we have $m$ weights, one corresponding to every input.  Thus for 128 units, we will have  $m$ weights.  `w` is a 2D tensor of shape $(128, m)$.\n",
    "- Input `input` is a vector (2D tensor) with `sample` examples, each represented with $m$ features.\n",
    "- Each unit in the dense layer has a bias term.   Hence `b` is a vector with 128 components. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqL1EcyheEHK"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "RaV3r0kXkZdX",
    "outputId": "2c5ee34c-412a-4a5a-9ba4-b29f44122241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of axes- w = 2\n",
      "Shape of w =  (2, 2)\n",
      "\n",
      "# of axes- input = 2\n",
      "Shape input =  (2, 2)\n",
      "\n",
      "# of axes- b = 1 \n",
      "Shape of b =  (2,)\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[1, 0.5], [2, 1]])\n",
    "print (\"# of axes- w = %d\"%w.ndim)\n",
    "print (\"Shape of w = \", w.shape)\n",
    "print ()\n",
    "\n",
    "input = np.array([[1, 2], [-1, 2]])\n",
    "print (\"# of axes- input = %d\"%input.ndim)\n",
    "print (\"Shape input = \", input.shape)\n",
    "print ()\n",
    "\n",
    "b = np.array([-2.0, 0.5])\n",
    "print (\"# of axes- b = %d \"%b.ndim)\n",
    "print (\"Shape of b = \", b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQtDwZ36U6om"
   },
   "source": [
    "Let's apply linear combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "PbvIfOzhTjFi",
    "outputId": "7062b7cd-711f-4c82-e8e4-2574a30ecc72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Shape of w =  (2, 2)\n",
      "Shape input =  (2, 2)\n",
      "Shape of b =  (2,)\n",
      "==================================================\n",
      "Shape of z =  (2, 2)\n",
      "==================================================\n",
      "[[-1.5  3.5]\n",
      " [-1.   6.5]]\n"
     ]
    }
   ],
   "source": [
    "z = np.dot(w, input) + b              # Element-wise addition\n",
    "\n",
    "print (\"==================================================\")\n",
    "print (\"Shape of w = \", w.shape)\n",
    "print (\"Shape input = \", input.shape)\n",
    "print (\"Shape of b = \", b.shape)\n",
    "print (\"==================================================\")\n",
    "print (\"Shape of z = \", z.shape)\n",
    "print (\"==================================================\")\n",
    "print (z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "438UjgoLU-Lt"
   },
   "source": [
    "Let's apply non-linear activation with `relu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "bR57LKOBWWrF",
    "outputId": "a6e7b4b9-d207-4b69-8e26-966b6dfed9d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output =  (2, 2)\n",
      "[[0.  3.5]\n",
      " [0.  6.5]]\n"
     ]
    }
   ],
   "source": [
    "output = np.maximum(0., z)                 # Element-wise relu\n",
    "print (\"Shape of output = \", output.shape)\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TlUjnqt8QGFn"
   },
   "source": [
    "Before that, we will visualize a few commonly used activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "GDl1k6PbOPi9",
    "outputId": "facd0217-04d1-4dd7-8ea1-cbae26dbcba8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'relu(x)')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# relu vialuzation\n",
    "x = np.linspace(-10, 10, 100)\n",
    "z = np.maximum(0., x)  \n",
    "plt.plot(x, z)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"relu(x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "Uf7YQNlDPDuU",
    "outputId": "65542877-65a9-4051-de15-fc71a06128a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'sigmoid(x)')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sigmoid activation\n",
    "import math\n",
    "x = np.linspace(-10, 10, 100)\n",
    "z = 1/(1+np.exp(-x)) \n",
    "\n",
    "plt.plot(x, z)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"sigmoid(x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHpLGKXyWPsX"
   },
   "source": [
    "## Element-wise additions\n",
    "\n",
    "Note that `relu` and tensor addition are both element-wise operations and hence can be parallelized.  The vectorized implementations exploit this characteristics for efficient implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "27MSePbL0krz",
    "outputId": "2d1af8d7-dcdb-475e-ff74-656e19a0b570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== z ============\n",
      "[[-1.5  3.5]\n",
      " [-1.   6.5]]\n",
      "=========== output ============\n",
      "[[0.  3.5]\n",
      " [0.  6.5]]\n"
     ]
    }
   ],
   "source": [
    "z = np.dot(w, input) + b\n",
    "output = np.maximum(0, z)\n",
    "print (\"=========== z ============\")\n",
    "print (z)\n",
    "print (\"=========== output ============\")\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvO1qUJ6YglX"
   },
   "source": [
    "## Broadcasting\n",
    "\n",
    "Employed to make two tensors involved in the operations compatible.  Concretely, let's say you want to add two tensors when their shaps differ:\n",
    "1. Axes are added to the smaller tensor to match the `ndim` of the larger tensor.  These axes are called `broadcast axes`.\n",
    "2. The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "bemIxhL_YmRc",
    "outputId": "94de1b2c-f61f-4b30-d868-c03fc60e9a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_1:  (32, 10)\n",
      "Original shape of x_2:  (10,)\n",
      "Shape of x_2 after adding a broadcast axis:  (1, 10)\n",
      "Shape of x_2 after broadcasting:  (32, 10)\n"
     ]
    }
   ],
   "source": [
    "x_1 = np.random.rand(32, 10)\n",
    "x_2 = np.random.rand(10,)\n",
    "\n",
    "print (\"Shape of x_1: \", x_1.shape)\n",
    "\n",
    "print (\"Original shape of x_2: \", x_2.shape)\n",
    "\n",
    "# Broadcasting\n",
    "# 1. Add an axis to match ndim of the larger tensor.\n",
    "x_2 = np.expand_dims(x_2, axis=0)\n",
    "print (\"Shape of x_2 after adding a broadcast axis: \", x_2.shape)\n",
    "\n",
    "# 2. Smaller tensor is repeated on the new axis.\n",
    "x_2 = np.repeat(x_2, 32, axis=0)\n",
    "print (\"Shape of x_2 after broadcasting: \", x_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "its_74o0k3EK"
   },
   "source": [
    "In actual implementation, the entries are not repeated, but the algorithms implements virtual repeatition operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S2xDuVrVkgKG",
    "outputId": "4e3942a1-c0d4-4d3d-90d2-c5bed0d2e7ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10)\n"
     ]
    }
   ],
   "source": [
    "#numpy implements broadcasting\n",
    "x_1 = np.random.rand(32, 10)\n",
    "x_2 = np.random.rand(10,)\n",
    "print((x_1 + x_2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5kkYDR7mQIw"
   },
   "source": [
    "\n",
    "##  Tensor dot\n",
    "\n",
    "Tensor dot is not an elementwise operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EG2iXJgCmepb",
    "outputId": "ce019b1a-de9c-4734-ab4c-4cacf84c71f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "  # compatibility check: both x and y are vectors\n",
    "  assert len(x.shape) == 1\n",
    "  assert len(y.shape) == 1\n",
    "  \n",
    "  # compatibility checks: vectors with the same number of elements\n",
    "  assert x.shape[0] == y.shape[0]\n",
    "  \n",
    "  z = 0.\n",
    "  \n",
    "  # performs element-wise product and then adds it up\n",
    "  for i in range(x.shape[0]):\n",
    "    z += x[i] * y[i]\n",
    "    \n",
    "  # returns scalar\n",
    "  return z\n",
    "\n",
    "print (naive_vector_dot(np.array([1, 2]), np.array([1, 2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWyrhBnhneMl"
   },
   "source": [
    "Matrix-vector dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SPlMy-IRndwB",
    "outputId": "c7f7f323-7a2b-499b-fc0d-9db4a1a40fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 5.]\n"
     ]
    }
   ],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "  # check: x is a matrix\n",
    "  assert len(x.shape) == 2\n",
    "  \n",
    "  # check: y is a vector\n",
    "  assert len(y.shape) == 1\n",
    "  \n",
    "  # check: make sure # of columns in x is equal to number of rows in y\n",
    "  assert x.shape[1] == y.shape[0]\n",
    "\n",
    "  z = np.zeros(x.shape[0])\n",
    "  for i in range(x.shape[0]):\n",
    "    z[i] = naive_vector_dot(x[i, :], y)\n",
    "  return z\n",
    "\n",
    "print (naive_matrix_vector_dot(np.array([[1, 2], [1,2]]), np.array([1, 2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oE-gR7Q1oR8k"
   },
   "source": [
    "Note that as soon as one of the two tensors has an `ndim` greater than 1, `dot` is no longer symmetric, which is to say that `dot(x, y)` isn’t the same as `dot(y, x)`.\n",
    "\n",
    "Let's look at the Numpy implementation of dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E_glA8T1ovMX",
    "outputId": "70252d83-39ff-40dd-e46f-b9accd678f6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "z = np.dot(np.array([1, 2]), np.array([1, 2]))\n",
    "print (z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yq758wdRmd4U"
   },
   "source": [
    "## Tensor Reshaping\n",
    "\n",
    "Reshaping is used to rearrange rows and columns of tensor to match the shape of target tensor.  The reshaped tensor has the same number of elements as the initial tensor. \n",
    "\n",
    "It is mainly used in data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "id": "pv5pv9t0p4Yn",
    "outputId": "c4746039-9a70-4e4f-f489-3bba90138516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [[0. 1.]\n",
      " [2. 3.]\n",
      " [4. 5.]]\n",
      "Shape of x: (3, 2)\n",
      "(3, 2)\n",
      "===========\n",
      "x after reshaping to (6,1)\n",
      "x = [[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]]\n",
      "New shape of x: (6, 1)\n",
      "===========\n",
      "x after reshaping to (2,3)\n",
      "x = [[0. 1. 2.]\n",
      " [3. 4. 5.]]\n",
      "New shape of x (2, 3)\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = np.array([[0., 1.],\n",
    "              [2., 3.],\n",
    "              [4., 5.]])\n",
    "print (\"x =\", x)\n",
    "\n",
    "print(\"Shape of x:\", x.shape)\n",
    "print(x.shape)\n",
    "print (\"===========\")\n",
    "\n",
    "# Reshaping the tensor to a \n",
    "\n",
    "x = x.reshape((6, 1))\n",
    "print (\"x after reshaping to (6,1)\")\n",
    "print (\"x =\", x)\n",
    "\n",
    "print (\"New shape of x:\", x.shape)\n",
    "print (\"===========\")\n",
    "\n",
    "x = x.reshape((2, 3))\n",
    "print (\"x after reshaping to (2,3)\")\n",
    "print (\"x =\", x)\n",
    "\n",
    "print (\"New shape of x\", x.shape)\n",
    "print (\"===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ox7sh1sdrcds"
   },
   "source": [
    "Transposition is a special case of reshaping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wmcF_xT4rgO5",
    "outputId": "81cd90af-361d-4852-a05d-33d93fb22046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2YSDjP5zjGr"
   },
   "source": [
    "# Neural net training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "27XWilUisX58"
   },
   "source": [
    "\n",
    "\n",
    "## Gradient based optimization\n",
    "\n",
    "Each layer in the neural network uses the following function to transform the input to the output:\n",
    "\n",
    "`output = relu(dot(W, input) + b)`\n",
    "\n",
    "In this expression, `W` and `b` are trainable parameter or weights of the layer.  They are called *kernels* and *bias* in the context of Keras API.\n",
    "\n",
    "We randomly initialize `W` and `b` to *small random values*.  Avoid initializing all parameters to 0 or any other numbers.  The training loop has the following steps:\n",
    "1. Draw a batch of training samples `x` and corresponding targets `y`.\n",
    "2. Run the network on `x` to obtain predictions `y_pred`.\n",
    "3. Compute the loss of the network on the batch, a measure of the mismatch\n",
    "between `y_pred` and `y`.\n",
    "4. Compute the gradient of the loss with respect to the network’s parameters (a\n",
    "backward pass).\n",
    "5. Move the parameters a little in the opposite direction from the gradient—for\n",
    "example `W -= step * gradient`—thus reducing the loss on the batch a bit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nwevnNTmzcWK"
   },
   "source": [
    "## Momentum based optimizers\n",
    "\n",
    "**Show the intuition of the approach with an analogy to the ball rolling down the slope.**\n",
    "\n",
    "Neural network loss function is full of lots of local minimas.  Once the algorithm reaches one of these local minimas, it is hard to come out of that.  In such cases, momentum based methods come to our rescue.\n",
    "\n",
    "The momentum based methods draws inspiration from physics.  Intuition based on the drawing: A ball rolling down the loss curve, if it has got sufficient momentum, it won't get stuck in local minima.  \n",
    "\n",
    "We use current slope (current  accelaration) and velocity based on past accelerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRQIc7qk2YP2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-67f91ee8852a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_current_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "past_velocity = 0.\n",
    "\n",
    "# Constant momentum factor\n",
    "momentum = 0.1\n",
    "\n",
    "while loss > 0.01:\n",
    "  w, loss, gradient = get_current_parameters()\n",
    "  \n",
    "  velocity = past_velocity * momentum + learning_rate * gradient\n",
    "  \n",
    "  # Get the new value for w based on momentum.\n",
    "  w = w + momentum * velocity - learning_rate * gradient\n",
    "  \n",
    "  # Update velocity\n",
    "  past_velocity = velocity\n",
    "  update_parameter(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBkGPr_j0QDk"
   },
   "source": [
    "# Revisit the Hello World TF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNL-EC8XDELY"
   },
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBJVFVpTDVeS"
   },
   "outputs": [],
   "source": [
    "print(\"Training Tensors\")\n",
    "print(\"=======================\")\n",
    "print(\"Number of dimensions in tensor: %d\"%x_train.ndim)\n",
    "print(\"Tensor shape: \", x_train.shape)\n",
    "print(\"Data type: %s\"%x_train.dtype)\n",
    "print(\"=======================\")\n",
    "print()\n",
    "print(\"Test Tensors\")\n",
    "print(\"=======================\")\n",
    "print(\"Number of dimensions in tensor: %d\"%x_test.ndim)\n",
    "print(\"Tensor shape: \", x_test.shape)\n",
    "print(\"Data type: %s\"%x_test.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfeL_A-DDGzw"
   },
   "source": [
    "Build the tf.keras.Sequential model by stacking layers. Choose an optimizer and loss function for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nJ5cNaLDEvC"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ap9Em4mLERJd"
   },
   "source": [
    "Now you understand that this network consists of a chain of two Dense layers, that\n",
    "each layer applies a few simple tensor operations to the input data, and that these\n",
    "operations involve weight tensors. Weight tensors, which are attributes of the layers,\n",
    "are where the knowledge of the network persists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZD5CxZloHZx1"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3GBMdrsER8M"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYjyQzvpEU4x"
   },
   "source": [
    "Now you understand that \n",
    "* `sparse_categorical_crossentropy` is the loss function that’s used as a feedback signal for learning the weight tensors,  and which the training phase will attempt to minimize.   We used this loss function since our output are integers between 0 to 9.\n",
    "* This reduction of the loss happens via minibatch stochastic gradient descent.  \n",
    "* The exact rules governing a specific use of gradient descent are defined by the `adam` optimizer passed as the first argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kTEM9uM6DI3T"
   },
   "source": [
    "Train and evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZjRh3KTlDLkb"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOnzfv_OFXU_"
   },
   "source": [
    "## TODO: make sure the batch size is accurate here.\n",
    "\n",
    "Now you understand what happens when you call fit: \n",
    "* The network will start to iterate on the training data in mini-batches of 128 samples, 5 times over (each iteration over\n",
    "all the training data is called an epoch). \n",
    "* At each iteration, the network will compute the gradients of the weights with regard to the loss on the batch, and update the weights\n",
    "accordingly.\n",
    "* After these 5 epochs, the network will have performed 2,345 gradient updates (469 per epoch), and the loss of the network will be \n",
    "sufficiently low that the network will be capable of classifying handwritten digits with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7XwyFONSJrrh"
   },
   "outputs": [],
   "source": [
    "# todo: show how prediction works on a single image and a batch of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPQpLOsg0V0c"
   },
   "source": [
    "# Summary\n",
    "\n",
    "In this module,  we studied mathematical foundations of deep learning.  You now have understanding of \n",
    "- Tensors\n",
    "- Input data representation with tensors\n",
    "- Data batches in tensors\n",
    "- Key operations in neural network and their low level details\n",
    "- Neural network training"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MathematicalFoundationsOfDL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
